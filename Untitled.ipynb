{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, pickle\n",
    "from collections import Counter, defaultdict\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Autocorrector:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize your data structures in the constructor.\"\"\"\n",
    "        self.UnigramCounts = pickle.load(file('data/grammarly_wikitionary.pickle', 'r')) #dict\n",
    "        self.BigramCounts = pickle.load(file(\"data/count_2w.pickle\",'r')) #dict\n",
    "        self.vocabulary = self.UnigramCounts.keys()\n",
    "        self.total = len(self.vocabulary)\n",
    "        # ----- Applying Knser-Ney Method -----\n",
    "        self.BeforeCounts = defaultdict(set)\n",
    "        self.AfterCounts = defaultdict(set)\n",
    "        for key in self.BigramCounts.keys():\n",
    "            first_word, second_word = key.split(' ')\n",
    "            self.AfterCounts[first_word].add(second_word)\n",
    "            self.BeforeCounts[second_word].add(first_word)\n",
    "\n",
    "\n",
    "    def __known(self, words):\n",
    "        #Return a set of the words subset that are actually in the vocabulary.\n",
    "        return {w for w in words if w.lower() in self.vocabulary}\n",
    "\n",
    "    def correct_word(self, word):\n",
    "        \"\"\"\n",
    "        Find the best spelling correction for this word.\n",
    "        Prefer edit 1, then 2; otherwise default to word itself.\n",
    "        \"\"\"\n",
    "        # ---------------- HELPFUL FUNCTIONS ----------------\n",
    "        def edits1(word_1):\n",
    "            #Return all strings that are one edit away from this word.\n",
    "            # ---------------- HELPFUL FUNCTION ----------------\n",
    "            def split_word(wrd):\n",
    "                #Return a list of all possible (first, rest) character pairs that comprise word.\n",
    "                return [(wrd[:i], wrd[i:]) \n",
    "                        for i in range(len(wrd)+1)]\n",
    "            # --------------------------------------------------\n",
    "            alphabet = \"abcdefghijklmnopqrstuvwxyz'\"\n",
    "            pairs      = split_word(word_1)\n",
    "            deletes    = [a+b[1:]           for (a, b) in pairs if b]\n",
    "            transposes = [a+b[1]+b[0]+b[2:] for (a, b) in pairs if len(b) > 1]\n",
    "            replaces   = [a+c+b[1:]         for (a, b) in pairs for c in alphabet if b]\n",
    "            inserts    = [a+c+b             for (a, b) in pairs for c in alphabet]\n",
    "            return set(deletes + transposes + replaces + inserts)\n",
    "        def edits2(word_2):\n",
    "            #Return all strings that are two edits away from this word.\n",
    "            return {e2 for e1 in edits1(word_2) for e2 in edits1(e1)}\n",
    "        # ------------------------------------------------\n",
    "        if self.__known([word]):  #the word in the vocabulary\n",
    "            return [(word, self.UnigramCounts[word])]\n",
    "        else: #the word not in the vocabulary\n",
    "            candidates = self.__known(edits1(word))\n",
    "            c = Counter({w: self.UnigramCounts[w] for w in candidates})\n",
    "            if c:\n",
    "                if c.most_common(1)[0][1] < 100000: #------------------------------> hyper-parameter\n",
    "                    candidates = candidates.union(self.__known(edits2(word))) \n",
    "                    c = Counter({w: self.UnigramCounts[w] for w in candidates})\n",
    "                return c.most_common(100)    #lists of tuple\n",
    "            else: # didn't found candidates\n",
    "                return [(word, 0)]\n",
    "\n",
    "\n",
    "    def __score(self, tupl):\n",
    "        \"\"\"\n",
    "        Takes a tuple and returns a score using Knser-Ney method\n",
    "        This score depends on the count of bigram and unigram\n",
    "        This score is used to correct a sentence\n",
    "        \"\"\"\n",
    "        kn_score = 0.0\n",
    "        d = 0.75\n",
    "        first_word, second_word = tupl\n",
    "        count1 = self.BigramCounts[' '.join(tupl).lower()]\n",
    "        if first_word == '<s>':\n",
    "            count2 = 10000000 #ten million\n",
    "        else:\n",
    "            count2 = self.UnigramCounts[first_word]\n",
    "        _lambda = d/(count2+1.)*len(self.AfterCounts[first_word])\n",
    "        if count1 == 0:\n",
    "            d = 0.9\n",
    "        p_continuation = float(len(self.BeforeCounts[second_word]))/self.total\n",
    "        first_term = ( (count1-d)/(count2+1.) )\n",
    "        if first_term == 0:\n",
    "            kn_score += (_lambda*p_continuation)\n",
    "        else:\n",
    "            kn_score += first_term + (_lambda*p_continuation)\n",
    "        return kn_score\n",
    "\n",
    "\n",
    "    def __custom_tokenize(self, sentence):\n",
    "        lst = word_tokenize(sentence)\n",
    "        if len(lst) == 1:\n",
    "            return [sentence]\n",
    "        output = []\n",
    "        for i in xrange(len(lst)-1):\n",
    "            if \"'\" == lst[i][0]:\n",
    "                continue\n",
    "            elif \"'\" == lst[i+1][0]:\n",
    "                output.append(lst[i]+lst[i+1])\n",
    "            else:\n",
    "                output.append(lst[i])\n",
    "        if \"'\" not in lst[i+1]:\n",
    "            output.append(lst[i+1])\n",
    "        return output\n",
    "\n",
    "\n",
    "    def correct_sentence(self, sentence):\n",
    "        def case_of(text):\n",
    "            #Return the case-function appropriate for text: upper, lower, title, or just str.\n",
    "            return (str.upper if text.isupper() else\n",
    "                    str.lower if text.islower() else\n",
    "                    str.title if text.istitle() else\n",
    "                    str)\n",
    "        output = ''\n",
    "        start_word = \"<s>\"\n",
    "        for wrd in self.__custom_tokenize(sentence):\n",
    "            if wrd in \",.;?!\":\n",
    "                output += wrd\n",
    "            elif wrd.isupper():\n",
    "                output += ' ' + wrd\n",
    "            else:\n",
    "                candidates = [(tupl[0], self.__score((start_word, tupl[0]))) for tupl in self.correct_word(wrd.lower())]\n",
    "                winner = max(candidates, key=lambda x: x[1])[0]\n",
    "                output += ' ' + case_of(wrd)(winner)\n",
    "                start_word = winner\n",
    "        return output.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------------------Create an instance---------------------\n",
    "model = Autocorrector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I low you so much in a continuous was'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.correct_sentence('I lov you so mych in a continous wai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arabic'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.correct_sentence('arabick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
